{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the libraries"
      ],
      "metadata": {
        "id": "lGzUehWeOXN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2"
      ],
      "metadata": {
        "id": "Vow-e_IPBBG0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mounting the drive"
      ],
      "metadata": {
        "id": "Q88rmQJtRgNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvhvvP-uRhMG",
        "outputId": "51ef3ba9-1197-4197-9b24-e34d7d8932ba"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading train and test annotations data"
      ],
      "metadata": {
        "id": "GrMuU-OItYAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to train files\n",
        "train_folder = \"/content/drive/MyDrive/VinDr/train_png\"\n",
        "output_train_folder = \"/content/drive/MyDrive/resized_train_images\"\n",
        "train_annotations_file = \"/content/drive/MyDrive/VinDr/annotations/processed_train_annotations.csv\"  # processed train annotations file\n",
        "\n",
        "# Paths to test files\n",
        "test_folder = \"/content/drive/MyDrive/VinDr/test_png\"\n",
        "output_test_folder = \"/content/drive/MyDrive/resized_test_images\"\n",
        "test_annotations_file = \"/content/drive/MyDrive/VinDr/annotations/processed_test_annotations.csv\"  # processed test annotations file"
      ],
      "metadata": {
        "id": "Szrh5c1uWIk_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to return all images paths from specified folder"
      ],
      "metadata": {
        "id": "yC3MWKh6Oo5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to return all images paths from specified folder\n",
        "def get_all_images_from_folder(base_folder):\n",
        "    image_paths = []\n",
        "    for subdir, _, files in os.walk(base_folder):  # os.walk() returns a 3-tuple containing dirpath, dirnames, filenames\n",
        "        for file in files:\n",
        "            if file.endswith('.png') or file.endswith('.jpg') or file.endswith('.jpeg'):\n",
        "            # if file.endswith(('.png', '.jpg', '.jpeg')):\n",
        "                image_paths.append(os.path.join(subdir, file))\n",
        "    return image_paths"
      ],
      "metadata": {
        "id": "4nnLR4_OEup4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to resize images"
      ],
      "metadata": {
        "id": "2zaBEpd7gApT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to resize images and update annotations\n",
        "def resize_images_and_update_annotations(images_paths, annotations, output_folder, target_size):\n",
        "\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    updated_annotations = []\n",
        "\n",
        "    for image_path in images_paths:\n",
        "        image_name = os.path.basename(image_path)\n",
        "        img = cv2.imread(image_path)\n",
        "\n",
        "        if img is not None:\n",
        "            original_height, original_width = img.shape[:2]\n",
        "\n",
        "            # Calculate scaling factors\n",
        "            scale = min(target_size / original_width, target_size / original_height)\n",
        "            new_width = int(original_width * scale)\n",
        "            new_height = int(original_height * scale)\n",
        "\n",
        "            # Resize image\n",
        "            resized_img = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "            # Create a padded image\n",
        "            padded_img = np.zeros((target_size, target_size, 3), dtype=np.uint8)\n",
        "            x_offset = (target_size - new_width) // 2\n",
        "            y_offset = (target_size - new_height) // 2\n",
        "            padded_img[y_offset:y_offset + new_height, x_offset:x_offset + new_width] = resized_img\n",
        "\n",
        "            # Save the padded image\n",
        "            cv2.imwrite(os.path.join(output_folder, image_name), padded_img)\n",
        "\n",
        "            # Update bounding boxes\n",
        "            image_id = os.path.splitext(image_name)[0]\n",
        "            image_annotations = annotations[annotations['image_id'] == image_id]\n",
        "\n",
        "            for _, row in image_annotations.iterrows():\n",
        "                # Check if bounding box values are None (NaN), and handle accordingly\n",
        "                if pd.isna(row['x_min']) or pd.isna(row['y_min']) or pd.isna(row['x_max']) or pd.isna(row['y_max']):\n",
        "                    # If any of the bounding box values are None, retain None in the updated annotations\n",
        "                    updated_annotations.append({\n",
        "                        'image_id': image_name,\n",
        "                        'class_name': row['class_name'],\n",
        "                        'x_min': None,\n",
        "                        'y_min': None,\n",
        "                        'x_max': None,\n",
        "                        'y_max': None,\n",
        "                        'class_id': row['class_id']\n",
        "                    })\n",
        "                else:\n",
        "                    x_min = int(row['x_min'] * scale + x_offset)\n",
        "                    y_min = int(row['y_min'] * scale + y_offset)\n",
        "                    x_max = int(row['x_max'] * scale + x_offset)\n",
        "                    y_max = int(row['y_max'] * scale + y_offset)\n",
        "\n",
        "                    updated_annotations.append({\n",
        "                        'image_id': image_name,\n",
        "                        'class_name': row['class_name'],\n",
        "                        'x_min': x_min,\n",
        "                        'y_min': y_min,\n",
        "                        'x_max': x_max,\n",
        "                        'y_max': y_max,\n",
        "                        'class_id': row['class_id']\n",
        "                    })\n",
        "\n",
        "    return updated_annotations"
      ],
      "metadata": {
        "id": "f6y7t0pZzoHw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMBTjSYyA-hc"
      },
      "outputs": [],
      "source": [
        "# for image_path in images_paths:\n",
        "#     image_name = os.path.basename(image_path)\n",
        "#     img = cv2.imread(image_path)\n",
        "\n",
        "#     if img is not None:\n",
        "#         original_height, original_width = img.shape[:2]\n",
        "\n",
        "#         # Calculate scaling factors\n",
        "#         scale = min(target_size / original_width, target_size / original_height)\n",
        "#         new_width = int(original_width * scale)\n",
        "#         new_height = int(original_height * scale)\n",
        "\n",
        "#         # Resize image\n",
        "#         resized_img = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "#         # Create a padded image\n",
        "#         padded_img = np.zeros((target_size, target_size, 3), dtype=np.uint8)\n",
        "#         x_offset = (target_size - new_width) // 2\n",
        "#         y_offset = (target_size - new_height) // 2\n",
        "#         padded_img[y_offset:y_offset + new_height, x_offset:x_offset + new_width] = resized_img\n",
        "\n",
        "#         # Save the padded image\n",
        "#         cv2.imwrite(os.path.join(output_folder, image_name), padded_img)\n",
        "\n",
        "#         # Update bounding boxes\n",
        "#         # Get the image name without the extension\n",
        "#         image_id = os.path.splitext(image_name)[0]\n",
        "\n",
        "#         # Use this stripped name for comparison\n",
        "#         image_annotations = annotations[annotations['image_id'] == image_id]\n",
        "\n",
        "#         for _, row in image_annotations.iterrows():\n",
        "#             # Check if bounding box values are None (NaN), and handle accordingly\n",
        "#             if pd.isna(row['x_min']) or pd.isna(row['y_min']) or pd.isna(row['x_max']) or pd.isna(row['y_max']):\n",
        "#                 # If any of the bounding box values are None, retain None in the updated annotations\n",
        "#                 updated_annotations.append({\n",
        "#                     'image_id': image_name,  # Use full image name here\n",
        "#                     'class_name': row['class_name'],\n",
        "#                     'x_min': None,\n",
        "#                     'y_min': None,\n",
        "#                     'x_max': None,\n",
        "#                     'y_max': None,\n",
        "#                     'class_id': row['class_id']\n",
        "#                 })\n",
        "#             else:\n",
        "#                 x_min = int(row['x_min'] * scale + x_offset)\n",
        "#                 y_min = int(row['y_min'] * scale + y_offset)\n",
        "#                 x_max = int(row['x_max'] * scale + x_offset)\n",
        "#                 y_max = int(row['y_max'] * scale + y_offset)\n",
        "\n",
        "#                 updated_annotations.append({\n",
        "#                     'image_id': image_name,\n",
        "#                     'class_name': row['class_name'],\n",
        "#                     'x_min': x_min,\n",
        "#                     'y_min': y_min,\n",
        "#                     'x_max': x_max,\n",
        "#                     'y_max': y_max,\n",
        "#                     'class_id': row['class_id']\n",
        "#                 })"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resizing train data"
      ],
      "metadata": {
        "id": "k5mRJUmZWDsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load train annotations\n",
        "train_annotations = pd.read_csv(train_annotations_file)"
      ],
      "metadata": {
        "id": "ORg-s5MWWU8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Target YOLO size\n",
        "target_size = 1024"
      ],
      "metadata": {
        "id": "-10La09-WsHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get paths of all train images from train directory\n",
        "train_images_paths = get_all_images_from_folder(train_folder)"
      ],
      "metadata": {
        "id": "MDgwJtyJwVtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resize train images\n",
        "updated_train_annotations = resize_images_and_update_annotations(train_images_paths, train_annotations, output_train_folder, target_size)"
      ],
      "metadata": {
        "id": "YBdAllSVv9hr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save updated train annotations\n",
        "df_updated_train_annotations = pd.DataFrame(updated_train_annotations)\n",
        "df_updated_train_annotations.to_csv(\"/content/drive/MyDrive/VinDr/annotations/resized_train_annotations.csv\", index=False)"
      ],
      "metadata": {
        "id": "am4-n2bjFxfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resizing test data"
      ],
      "metadata": {
        "id": "FL0zWPzvxMr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load test annotations\n",
        "test_annotations = pd.read_csv(test_annotations_file)"
      ],
      "metadata": {
        "id": "G7cGCGRcxON3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get paths of all test images from train directory\n",
        "test_images_paths = get_all_images_from_folder(test_folder)"
      ],
      "metadata": {
        "id": "ibzdbJvNxefO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resize test images\n",
        "updated_test_annotations = resize_images_and_update_annotations(test_images_paths, test_annotations, output_test_folder, 1024)"
      ],
      "metadata": {
        "id": "woIbziKrxjdB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save updated test annotations\n",
        "df_updated_test_annotations = pd.DataFrame(updated_test_annotations)\n",
        "df_updated_test_annotations.to_csv(\"/content/drive/MyDrive/VinDr/annotations/resized_test_annotations.csv\", index=False)"
      ],
      "metadata": {
        "id": "iKLn8rV8xlgT"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}